# Тестовое задание

## Содержание
1. [Задача](#Задача)
2. [Запуск](#Запуск)
3. [Пример работы](#Пример-работы)
4. [Описание решения](#Описание-решения)
5. [Дополнительно](#Дополнительно)

## Задача
Необходимо на основе изображения/depth мапы/облака точек определить область захвата случайного объекта для манипулятора с присосками и оценить ее размеры. Это должна быть наибольшая плоская поверхность со стороны захвата (сверху).  

## Запуск
Для запуска программы необходимо установить зависимости из requirements.txt
```bash
conda create --name items_picker python=3.8
conda activate items_picker
pip install -r requirements.txt
```
Теперь необходимо создать конгфиг для камеры. Пример для RealSense L515 находится в файле [**l515.json**](/configs/l515.json).  
После этого можно запустить программу с указанием пути к конфигурационному файлу.
Все необходимые веса моделей будут загружены автоматически.
```bash
items_picker/items_picker.py configs/l515.json
```

## Пример работы
Больше примеров можно найти в директории [**docs**](/docs)
![image](/docs/example_3.png)
![image](/docs/example_4.png)

## Описание решения
Для сегментации объектов на изображении использовались *zero-shot* модели:
- [**CLIPSeg**](https://github.com/timojl/clipseg) - для сегментации объектов на изображении по текстовому описанию
- [**SAM**](https://github.com/facebookresearch/segment-anything/tree/main) - для уточнения полученных из CLIPSeg масок объектов

Для определения области захвата объекта применены алгоритмы:
- [**DBSCAN**](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) - для кластеризации точек облака и нахождения отдельных объектов
- [**RANSAC**](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html) - для нахождения плоскости в кластере точек

## Дополнительно
Проведя эксперименты с различными моделями, было выявлено, что комбинация CLIPSeg и SAM показывает хорошие для предобученных моделей результаты. Однако, для улучшения качества сегментации объектов на изображении, можно использовать другие модели, например, Mask R-CNN, YOLOv9 и другие.  
Существующее решение можно улучшить, заменив CLIPSeg на GroundingDINO, модель для детекции объектов по текстовому описанию. В данном случае я не использовал эту модель, так как она очень тяжелая и требует значителбно больше видеопамяти. 
Также, можно применить End-to-End методы для определения точки захвата объекта, например, [**CLIPort**](https://cliport.github.io/) или [**GraspNet**](https://github.com/graspnet/graspnetAPI).
